{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import os\n",
    "import pickle\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "# nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import (accuracy_score, f1_score, precision_score, recall_score)\n",
    "from sklearn.model_selection import (GridSearchCV, KFold, RandomizedSearchCV, learning_curve)\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list of stopwords\n",
    "stopwords_list = list(stopwords.words('english'))\n",
    "stopwords_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to display the evaluation metrics of the different models\n",
    "def show_eval_scores(model, test_set, model_name):\n",
    "    \"\"\"Function to show to different evaluation score of the model passed\n",
    "    on the test set.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model: scikit-learn object\n",
    "        The model whose scores are to be shown.\n",
    "    test_set: pandas dataframe\n",
    "        The dataset on which the score of the model is to be shown.\n",
    "    model_name: string\n",
    "        The name of the model.\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(test_set['news'])\n",
    "    y_true = test_set['label']\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    \n",
    "    print('Report for ---> {}'.format(model_name))\n",
    "    print('Accuracy is: {}'.format(accuracy))\n",
    "    print('F1 score is: {}'.format(f1))\n",
    "    print('Precision score is: {}'.format(precision))\n",
    "    print('Recall score is: {}'.format(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the datasets\n",
    "train_data = pd.read_csv('../datasets/train.csv')\n",
    "valid_data = pd.read_csv('../datasets/valid.csv')\n",
    "test_data = pd.read_csv('../datasets/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Viewing random rows of all the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train dataset size: {}'.format(train_data.shape))\n",
    "print('Test dataset size: {}'.format(test_data.shape))\n",
    "print('Valid dataset size: {}'.format(valid_data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining train_data and valid_data into a single training set as GridSearchCV with 5 fold cross validation will be used for hyperparameter tuning the different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = pd.concat([train_data, valid_data], ignore_index=True)\n",
    "print('Training set size: {}'.format(training_set.shape))\n",
    "training_set.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a CountVectorizer object and analyzing the training set\n",
    "Bag-of-Words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countV = CountVectorizer()\n",
    "train_count = countV.fit_transform(training_set['news'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countV.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(countV.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building and tuning Logistic Regression pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_pipeline = Pipeline([\n",
    "#     ('lrCV', CountVectorizer(stop_words=stopwords_list)),\n",
    "#     ('lr_clf', LogisticRegression(random_state=42, n_jobs=-1))\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid = [\n",
    "#     {\n",
    "#         'lrCV__lowercase': [True, False],\n",
    "#         'lrCV__ngram_range': [(1, 1), (1, 2), (1, 3), (1, 4)],\n",
    "#         'lr_clf__C': [0.0001, 0.00005, 0.00001]\n",
    "#     }\n",
    "# ]\n",
    "\n",
    "# lr_gs = GridSearchCV(lr_pipeline, param_grid, scoring='f1', n_jobs=-1, cv=5, verbose=1)\n",
    "# lr_gs.fit(training_set['news'], training_set['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pipeline = Pipeline([\n",
    "    ('lrCV', CountVectorizer(stop_words=stopwords_list, lowercase=True, ngram_range=(1, 1))),\n",
    "    ('lr_clf', LogisticRegression(C=0.0001, random_state=42, n_jobs=-1))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pipeline.fit(training_set['news'], training_set['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_eval_scores(lr_pipeline, test_data, 'Logistic Regression Count Vectorizer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building and tuning Naive Bayes pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nb_pipeline = Pipeline([\n",
    "#     ('nb_CV', CountVectorizer(stop_words=stopwords_list)),\n",
    "#     ('nb_clf', MultinomialNB())\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid = {\n",
    "#     'nb_clf__alpha': [i/10.0 for i in range(60, 71)],\n",
    "#     'nb_CV__lowercase': [True, False],\n",
    "#     'nb_CV__ngram_range': [(1, 1), (1, 2), (1, 3), (1, 4)]\n",
    "# }\n",
    "\n",
    "# nb_gs = GridSearchCV(nb_pipeline, param_grid, scoring='f1', cv=5, n_jobs=-1, verbose=1)\n",
    "# nb_gs.fit(training_set['news'], training_set['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_pipeline = Pipeline([\n",
    "    ('nb_CV', CountVectorizer(stop_words=stopwords_list, lowercase=True, ngram_range=(1, 4))),\n",
    "    ('nb_clf', MultinomialNB(alpha=6.8))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_pipeline.fit(training_set['news'], training_set['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_eval_scores(nb_pipeline, test_data, 'Naive Bayes Count Vectorizer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building and tuning SVM classifier pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm_pipeline = Pipeline([\n",
    "#     ('svm_CV', CountVectorizer(stop_words=stopwords_list)),\n",
    "#     ('svm_clf', SVC(random_state=42))\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid = [\n",
    "#     {\n",
    "#         'svm_CV__lowercase': [True, False],\n",
    "#         'svm_CV__ngram_range': [(1, 1), (1, 2), (1, 3), (1, 4)],\n",
    "#         'svm_clf__kernel': ['poly'],\n",
    "#         'svm_clf__degree': [1, 2, 3]\n",
    "#     },\n",
    "#     {\n",
    "#         'svm_CV__lowercase': [True, False],\n",
    "#         'svm_CV__ngram_range': [(1, 1), (1, 2), (1, 3), (1, 4)],\n",
    "#         'svm_clf__kernel': ['rbf'],\n",
    "#         'svm_clf__gamma': [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "#     }\n",
    "# ]\n",
    "\n",
    "# svm_gs = GridSearchCV(svm_pipeline, param_grid, scoring='f1', n_jobs=-1, cv=5, verbose=1)\n",
    "# svm_gs.fit(training_set['news'], training_set['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm_gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_pipeline = Pipeline([\n",
    "    ('svm_CV', CountVectorizer(stop_words=stopwords_list, lowercase=False, ngram_range=(1, 1))),\n",
    "    ('svm_clf', SVC(random_state=42, gamma=1.0, kernel='rbf'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_pipeline.fit(training_set['news'], training_set['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_eval_scores(svm_pipeline, test_data, 'SVM Classifier Count Vectorizer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building and Tuning Random Forest Classifier pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_pipeline = Pipeline([\n",
    "#     ('rf_CV', CountVectorizer(stop_words=stopwords_list)),\n",
    "#     ('rf_clf', RandomForestClassifier(n_jobs=-1, random_state=42))\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid = {\n",
    "#     'rf_CV__lowercase': [True, False],\n",
    "#     'rf_CV__ngram_range': [(1, 1), (1, 2), (1, 3), (1, 4), (1, 5)],\n",
    "#     'rf_clf__n_estimators': [200, 300, 400, 500],\n",
    "#     'rf_clf__max_depth': [i for i in range(8, 13)],\n",
    "#     'rf_clf__max_features': ['auto', 'sqrt', 'log2']\n",
    "# }\n",
    "# rf_gs = GridSearchCV(rf_pipeline, param_grid, scoring='f1', cv=5, verbose=1, n_jobs=-1)\n",
    "# rf_gs.fit(training_set['news'], training_set['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pipeline = Pipeline([\n",
    "    ('rf_CV', CountVectorizer(stop_words=stopwords_list, lowercase=False, ngram_range=(1, 1))),\n",
    "    ('rf_clf', RandomForestClassifier(max_depth=12, n_estimators=300, n_jobs=-1, random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pipeline.fit(training_set['news'], training_set['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_eval_scores(rf_pipeline, test_data, 'Random Forest Classifier Count Vectorizer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building a Voting Classifier using the above created models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_voting_pipeline = Pipeline([\n",
    "    ('rf_CV', CountVectorizer(stop_words=stopwords_list, lowercase=False, ngram_range=(1, 1))),\n",
    "    ('rf_clf', RandomForestClassifier(max_depth=12, n_estimators=300, n_jobs=-1, random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_voting_pipeline = Pipeline([\n",
    "    ('svm_CV', CountVectorizer(stop_words=stopwords_list, lowercase=False, ngram_range=(1, 1))),\n",
    "    ('svm_clf', SVC(random_state=42, gamma=1.0, kernel='rbf', probability=True))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_voting_pipeline = Pipeline([\n",
    "    ('nb_CV', CountVectorizer(stop_words=stopwords_list, lowercase=True, ngram_range=(1, 4))),\n",
    "    ('nb_clf', MultinomialNB(alpha=6.8))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_voting_pipeline = Pipeline([\n",
    "    ('lrCV', CountVectorizer(stop_words=stopwords_list, lowercase=True, ngram_range=(1, 1))),\n",
    "    ('lr_clf', LogisticRegression(C=0.0001,random_state=42, n_jobs=-1))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_classifier = VotingClassifier(estimators=[\n",
    "    ('lr', lr_voting_pipeline), ('nb', nb_voting_pipeline),\n",
    "    ('svm', svm_voting_pipeline), ('rf', rf_voting_pipeline)], voting='soft', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_classifier.fit(training_set['news'], training_set['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_eval_scores(voting_classifier, test_data, 'Voting Classifier(soft) Count Vectorizer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the voting classifier model for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(voting_classifier, open(os.path.join('../models', 'voting_classifier_count_vectorizer.pkl'), 'wb'))"
   ]
  },
  {
   "source": [
    "#### Building a Boosting Classifier Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boosting_classfier = xgb.XGBClassifier(objective='binary:logistic', random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boosting_classfier.fit(training_set['news'], training_set['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_eval_scores(boosting_classfier, test_data, 'Boosting Classifier(XGBOOST) Count Vectorizer')"
   ]
  },
  {
   "source": [
    "#### Saving the boosting classifier model for the future use"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(boosting_classfier, open(os.path.join('../models', 'boosting_classifier.pkl'), 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}